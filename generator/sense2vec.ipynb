{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanatan/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2024-04-11 07:56:13.755800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 07:56:14.360049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-11 07:56:14.360110: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-11 07:56:17.205709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-11 07:56:17.206100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-11 07:56:17.206212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/sanatan/.local/lib/python3.8/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "from sense2vec import Sense2Vec\n",
    "s2v = Sense2Vec().from_disk('s2v_old')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model= SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "def get_answer_and_distractor_embeddings(answer,candidate_distractors):\n",
    "  answer_embedding = model.encode([answer])\n",
    "  distractor_embeddings = model.encode(candidate_distractors)\n",
    "  return answer_embedding,distractor_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def mmr(doc_embedding: np.ndarray,\n",
    "        word_embeddings: np.ndarray,\n",
    "        words: List[str],\n",
    "        top_n: int = 5,\n",
    "        diversity: float = 0.9) -> List[Tuple[str, float]]:\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate MMR\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [(words[idx], round(float(word_doc_similarity.reshape(1, -1)[0][idx]), 4)) for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word  chloroplasts\n",
      "Best sense  chloroplasts|NOUN\n",
      "[('chloroplast|NOUN', 0.8633), ('living_cells|NOUN', 0.823), ('plant_cells|NOUN', 0.8217), ('photosynthesis|NOUN', 0.8113), ('eukaryotic_cells|NOUN', 0.8112), ('bacterium|NOUN', 0.8036), ('mitochondria|NOUN', 0.7893), ('cells|NOUN', 0.7892), ('other_cells|NOUN', 0.7879), ('host_cells|NOUN', 0.7868), ('ribosomes|NOUN', 0.7797), ('new_cells|NOUN', 0.7789), ('organisms|NOUN', 0.7787), ('cancer_cells|NOUN', 0.7781), ('other_organisms|NOUN', 0.7752), ('organic_material|NOUN', 0.7743), ('organism|NOUN', 0.7736), ('microbes|NOUN', 0.7735), ('prokaryotes|NOUN', 0.7735), ('fungi|NOUN', 0.7732)]\n",
      "chloroplast|NOUN\n",
      "living_cells|NOUN\n",
      "plant_cells|NOUN\n",
      "photosynthesis|NOUN\n",
      "eukaryotic_cells|NOUN\n",
      "bacterium|NOUN\n",
      "mitochondria|NOUN\n",
      "cells|NOUN\n",
      "other_cells|NOUN\n",
      "host_cells|NOUN\n",
      "ribosomes|NOUN\n",
      "new_cells|NOUN\n",
      "organisms|NOUN\n",
      "cancer_cells|NOUN\n",
      "other_organisms|NOUN\n",
      "organic_material|NOUN\n",
      "organism|NOUN\n",
      "microbes|NOUN\n",
      "prokaryotes|NOUN\n",
      "fungi|NOUN\n",
      "['chloroplast', 'living cells', 'plant cells', 'photosynthesis', 'eukaryotic cells', 'bacterium', 'mitochondria', 'cells', 'other cells', 'host cells', 'ribosomes', 'new cells', 'organisms', 'cancer cells', 'other organisms', 'organic material', 'organism', 'microbes', 'prokaryotes', 'fungi']\n"
     ]
    }
   ],
   "source": [
    "originalword = \"chloroplasts\"\n",
    "word = originalword.lower()\n",
    "\n",
    "word = word.replace(\" \", \"_\")\n",
    "\n",
    "print (\"word \",word)\n",
    "sense = s2v.get_best_sense(word)\n",
    "\n",
    "print (\"Best sense \",sense)\n",
    "most_similar = s2v.most_similar(sense, n=20)\n",
    "print (most_similar)\n",
    "\n",
    "distractors = []\n",
    "\n",
    "for each_word in most_similar:\n",
    "  print(each_word[0])\n",
    "  append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \")\n",
    "  if append_word not in distractors and append_word != originalword:\n",
    "      distractors.append(append_word)\n",
    "\n",
    "print (distractors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_embedd, distractor_embedds = get_answer_and_distractor_embeddings(originalword,distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chloroplast\n",
      "------------------->\n",
      "microbes\n",
      "cancer cells\n",
      "organic material\n"
     ]
    }
   ],
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
